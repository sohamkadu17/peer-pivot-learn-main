# Correlation Matrix Analysis - YouTube Toxicity Classifier

**Generated**: December 1, 2025  
**Dataset**: YouTube Toxicity Data (1,000 samples)  
**Analysis**: Feature-Toxicity Correlation Analysis

---

## üìä What is a Correlation Matrix?

A **correlation matrix** shows the statistical relationships between different features (words/phrases) and the target variable (toxicity). The correlation coefficient ranges from **-1 to +1**:

- **+1**: Perfect positive correlation (feature increases with toxicity)
- **0**: No correlation (feature is independent of toxicity)
- **-1**: Perfect negative correlation (feature decreases with toxicity)

---

## üéØ Interpretation Guide

### Positive Correlation (Toxic Indicators)
Features with **positive correlation** are strongly associated with toxic comments:
- Higher values mean these words/phrases appear more frequently in toxic content
- The model learns to flag comments containing these features as potentially toxic

### Negative Correlation (Non-Toxic Indicators)
Features with **negative correlation** are strongly associated with non-toxic comments:
- Lower (more negative) values mean these words/phrases appear more in safe content
- The model learns to classify comments with these features as non-toxic

---

## üìà Top 30 Feature-Toxicity Correlations

### üî¥ Strongest Toxic Indicators (Positive Correlation)

| Rank | Feature | Correlation | Interpretation |
|------|---------|-------------|----------------|
| 1 | **shit** | +0.1946 | Strongest toxic indicator - profanity |
| 2 | **fuck** | +0.1895 | Very strong profanity signal |
| 3 | **over** | +0.1549 | Context-dependent (often in aggressive phrases) |
| 4 | **fucking** | +0.1492 | Strong profanity modifier |
| 5 | **run** | +0.1461 | Often in threatening context ("run them over") |
| 6 | **thug** | +0.1310 | Potentially discriminatory/derogatory term |
| 7 | **them** | +0.1273 | Often in aggressive context |
| 8 | **idiot** | +0.1252 | Direct insult |
| 9 | **ass** | +0.1221 | Profanity/insult |
| 10 | **bullshit** | +0.1200 | Strong profanity |
| 11 | **shoot** | +0.1164 | Violent language |
| 12 | **run them** | +0.1133 | Threatening phrase (bigram) |
| 13 | **them over** | +0.1130 | Threatening phrase continuation |
| 14 | **out of** | +0.1106 | Often in aggressive expressions |
| 15 | **a** | +0.1090 | High frequency in aggressive context |
| 16 | **of shit** | +0.1090 | Profanity phrase (bigram) |
| 17 | **piece of** | +0.1086 | Often precedes insult ("piece of shit") |
| 18 | **those** | +0.1082 | Often in divisive/othering language |
| 19 | **bitch** | +0.1063 | Derogatory/sexist term |
| 20 | **stupid** | +0.1028 | Direct insult |
| 21 | **an idiot** | +0.0956 | Complete insult phrase (bigram) |
| 22 | **racists** | +0.0954 | Accusatory/inflammatory term |
| 23 | **own** | +0.0950 | Context-dependent |

### üü¢ Strongest Non-Toxic Indicators (Negative Correlation)

| Rank | Feature | Correlation | Interpretation |
|------|---------|-------------|----------------|
| 1 | **video** | -0.1366 | Strong indicator of constructive comment about content |
| 2 | **peggy** | -0.1240 | Proper name (positive context) |
| 3 | **thank you** | -0.1220 | Gratitude expression (bigram) |
| 4 | **thank** | -0.1210 | Gratitude word |
| 5 | **truth** | -0.1119 | Discussion/debate term (constructive) |
| 6 | **but** | -0.1073 | Conjunction often in reasoned arguments |
| 7 | **the truth** | -0.0963 | Discussion phrase (bigram) |

---

## üîç Key Insights from Correlation Analysis

### 1. **Profanity is the Strongest Signal**
- The top 4 toxic indicators are all profanity-related terms
- Profanity has correlation coefficients ranging from 0.12 to 0.19
- This explains why the model achieves 72% accuracy - profanity is a reliable toxicity marker

### 2. **Bigrams (2-word phrases) Add Context**
- **"run them"** (+0.1133) and **"them over"** (+0.1130) show threatening intent
- **"piece of"** (+0.1086) often precedes **"shit"** in insults
- **"an idiot"** (+0.0956) captures complete insult phrase
- **"thank you"** (-0.1220) is stronger than just **"thank"** (-0.1210)

### 3. **Context Matters**
- Some common words like **"over"**, **"run"**, **"them"** show positive correlation
- These aren't inherently toxic but appear frequently in aggressive contexts
- Example: "run them over" is threatening despite containing common words

### 4. **Gratitude is Highly Non-Toxic**
- **"thank"** and **"thank you"** are among the strongest non-toxic indicators
- Comments expressing appreciation are rarely toxic

### 5. **Content-Focused Comments are Safe**
- **"video"** (-0.1366) is the strongest non-toxic indicator
- Comments discussing the content rather than attacking people are non-toxic
- Proper names like **"peggy"** (-0.1240) often appear in positive contexts

### 6. **Correlation Strength is Moderate**
- Maximum absolute correlation is only 0.19 (not close to 1.0)
- This indicates toxicity is multifaceted, not determined by single words
- The model needs to consider combinations of features for accurate predictions

---

## üìä Correlation Matrix Visualization

The generated `correlation_matrix.png` shows:

### Structure
- **30x30 matrix** displaying correlations between top 30 features
- **Lower triangle** shown (upper triangle masked for clarity)
- **Color coding**:
  - üî¥ Red shades: Positive correlations
  - üîµ Blue shades: Negative correlations
  - ‚ö™ White: Near-zero correlation

### What to Look For

1. **Diagonal**: Always 1.0 (perfect self-correlation)
2. **Bottom row/Right column**: "Toxicity" correlations with each feature
3. **Feature-Feature correlations**: Shows which words often appear together
4. **Clusters**: Groups of features that co-occur frequently

### Reading the Matrix

**Example interpretations**:
- If "shit" and "bullshit" have high correlation ‚Üí they often appear together
- If "thank" and "video" have positive correlation ‚Üí grateful comments often mention video
- If "fuck" and "thank" have negative correlation ‚Üí they rarely appear together

---

## üéì Statistical Significance

### Correlation Coefficient Interpretation

| Absolute Value | Strength | Interpretation |
|----------------|----------|----------------|
| 0.00 - 0.09 | Negligible | Very weak or no relationship |
| 0.10 - 0.19 | Weak | Slight relationship (most of our features) |
| 0.20 - 0.39 | Moderate | Noticeable relationship |
| 0.40 - 0.59 | Strong | Clear relationship |
| 0.60 - 0.79 | Very Strong | Very clear relationship |
| 0.80 - 1.00 | Extremely Strong | Near-perfect relationship |

### Our Results
- **Range**: -0.14 to +0.19 (weak correlations)
- **Why low?**: Toxicity is complex - no single word perfectly predicts toxicity
- **Multiple features**: Model combines many weak signals for strong prediction

---

## üßÆ How Correlations Help the Model

### 1. **Feature Selection**
- Features with higher absolute correlation are more informative
- Low-correlation features can be removed to reduce noise

### 2. **Understanding Predictions**
- High correlation features heavily influence predictions
- Explains why certain comments get flagged

### 3. **Identifying Bias**
- Check if neutral words (e.g., names, places) have unexpected correlations
- Detect potential discriminatory patterns

### 4. **Model Improvement**
- Features with near-zero correlation can be dropped
- Focus on engineering better features that correlate more strongly

---

## üìÅ Correlation Data Files

### `correlation_matrix.png`
- **Type**: High-resolution heatmap (300 DPI)
- **Size**: 16x14 inches
- **Features**: Top 30 features + Toxicity
- **Use**: Visual representation for reports/presentations

### `feature_toxicity_correlation.csv`
- **Columns**: Feature, Correlation, Abs_Correlation
- **Rows**: 30 (top features by absolute correlation)
- **Sorted**: By absolute correlation (descending)
- **Use**: Detailed numerical analysis, spreadsheet import

---

## üéØ Practical Applications

### 1. **Content Moderation Strategy**
Use correlation insights to:
- **Flag high-risk words**: Prioritize comments with top toxic features
- **Reduce false positives**: Don't over-flag comments with constructive terms
- **Context awareness**: Consider bigrams and word combinations

### 2. **Feature Engineering**
Improve the model by:
- **Creating more bigrams**: "thank you", "piece of shit", etc.
- **Weighting features**: Give higher weight to strongly correlated features
- **Removing noise**: Drop features with correlation < 0.05

### 3. **Explainable AI**
Use correlations to:
- **Explain predictions**: Show users which words triggered flagging
- **Build trust**: Demonstrate model isn't arbitrary
- **Appeal process**: Allow users to see reasoning

### 4. **Dataset Quality Check**
Identify issues:
- **Unexpected correlations**: Neutral words shouldn't be highly correlated
- **Missing features**: Important toxic words not in top 30?
- **Class imbalance**: Correlations affected by imbalanced data

---

## üî¨ Advanced Analysis

### Multicollinearity Check

If two features have very high correlation with each other (e.g., > 0.8):
- They provide redundant information
- One can be removed without losing predictive power
- Reduces model complexity and overfitting risk

**Example from our data**:
- "run them" and "them over" likely have high correlation (part of same phrase)
- Could combine into single trigram: "run them over"

### Partial Correlations

Current analysis shows **zero-order correlations** (direct relationships).
**Partial correlations** would show relationships after controlling for other variables:
- More accurate representation of true relationships
- Removes confounding effects
- Requires more complex statistical analysis

---

## üìä Comparison: Correlation vs Model Coefficients

### Correlation Analysis
- **Purpose**: Understand linear relationships
- **Method**: Statistical measure of association
- **Scope**: Bivariate (feature vs toxicity)

### Model Coefficients
- **Purpose**: Quantify feature importance in predictions
- **Method**: Learned weights from Logistic Regression
- **Scope**: Multivariate (considers all features together)

### Why They Differ
- **Model coefficients** account for interactions between features
- **Correlations** only measure individual feature-target relationships
- Model can learn that some correlated features are redundant

**Example**:
- "shit" has correlation = +0.19
- "shit" has model coefficient = +3.47
- Coefficient is scaled differently but confirms importance

---

## üéì For Academic Reports

### Recommended Report Sections

#### 1. Correlation Analysis
- Include `correlation_matrix.png` as a figure
- Reference `feature_toxicity_correlation.csv` table
- Discuss top 5 positive and negative correlations

#### 2. Feature Importance Discussion
- Compare correlations to model coefficients
- Explain why certain features are important
- Discuss implications for toxicity detection

#### 3. Methodology
- Explain correlation calculation (Pearson's r)
- Justify using top 30 features for visualization
- Discuss limitations of correlation analysis

#### 4. Interpretation
- What correlations reveal about toxicity patterns
- How correlations inform model decisions
- Potential biases or issues identified

### Key Figures

**Figure 1: Correlation Matrix Heatmap**
- Caption: "Correlation matrix showing relationships between top 30 features and toxicity label. Red indicates positive correlation (toxic), blue indicates negative correlation (non-toxic)."

**Table 1: Top Feature Correlations**
- Include top 10 positive and top 10 negative correlations
- Source from `feature_toxicity_correlation.csv`

---

## ‚úÖ Summary

### Key Findings

1. **Profanity dominates**: Top 4 toxic indicators are all profanity (correlation: 0.12-0.19)
2. **Weak correlations**: Maximum |r| = 0.19 indicates toxicity is multifaceted
3. **Gratitude is safe**: "thank you" and "thank" are strongest non-toxic signals
4. **Context matters**: Common words like "over", "run" show toxicity in context
5. **Bigrams help**: 2-word phrases provide better context than individual words

### Model Implications

- **72% accuracy** is reasonable given weak individual correlations
- Model successfully combines many weak signals for strong predictions
- Feature engineering (bigrams, trigrams) could improve performance
- No single feature perfectly predicts toxicity (max r = 0.19)

### Next Steps

1. **Feature engineering**: Create more contextual bigrams/trigrams
2. **Threshold tuning**: Adjust classification threshold based on use case
3. **Deep learning**: Use embeddings to capture richer semantic relationships
4. **Dataset expansion**: More diverse data could reveal stronger patterns

---

## üìû Technical Notes

### Calculation Method
```python
# Point-biserial correlation (binary target)
for each feature:
    correlation = pearsonr(feature_values, toxicity_labels)
```

### Data Transformation
- TF-IDF values (sparse matrix) ‚Üí Dense array
- Binary toxicity labels (0/1)
- Top 30 features selected by absolute correlation

### Visualization
- Seaborn heatmap with 'coolwarm' colormap
- Upper triangle masked for clarity
- Annotations show exact correlation values
- Square cells for easy reading

---

**Analysis Complete** ‚úÖ  
**Files Generated**: `correlation_matrix.png`, `feature_toxicity_correlation.csv`  
**Ready for**: Academic reports, presentations, further analysis
